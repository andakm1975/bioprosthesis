# Bioprosthesis — голосовое управление бионической кистью

Проект для распознавания голосовых команд и управления бионической кистью через ESP32.
Нейросетевая модель обрабатывает звук (с ПК или Raspberry Pi), после распознавания команда отправляется на контроллер протеза.

---

## Возможности
- Предобработка аудио и извлечение признаков (спектрограммы/МFCC).
- Инференс обученной модели (`*.h5`) для распознавания команд.
- Подготовка датасета и дообучение модели в Jupyter Notebook.
- Передача команд на ESP32 (ESP-NOW/Serial) — базовая интеграция.

---

## Структура репозитория
.
├─ main.py # Точка входа: инференс/утилиты
├─ Audio_Lerning_AutoEncoder.ipynb # Эксперименты с автоэнкодером
├─ audio-prepare.ipynb # Подготовка и нарезка аудио
├─ input/ # Исходные аудиофайлы для тестов
├─ output/ # Результаты обработки/логов
├─ models/ # Рекомендуемая папка для *.h5
└─ README.md



## Требования

- Python 3.10+
- Рекомендуемые пакеты (создайте `requirements.txt` при необходимости):
numpy
scipy
librosa
soundfile
tensorflow>=2.10
scikit-learn
matplotlib



## Установка

```bash
# Клонирование
git clone https://github.com/andakm1975/bioprosthesis.git
cd bioprosthesis

# Виртуальная среда (Windows)
python -m venv .venv
.\.venv\Scripts\activate

# Виртуальная среда (Linux/macOS)
# python -m venv .venv && source .venv/bin/activate

# Зависимости
pip install -r requirements.txt
Быстрый старт (инференс)
Положите одну или несколько записей команд (WAV/OGG) в input/ и модель в models/.

bash
Копировать код
python main.py --model ./models/new_model1.h5 --in ./input --out ./output
Аргументы main.py (рекомендуемый интерфейс):

--model — путь к файлу модели .h5

--in — папка с входными аудио

--out — папка для результатов/логов

--realtime — (опц.) режим работы с микрофоном

--espnow / --serial — (опц.) способ отправки команды на ESP32

--threshold — (опц.) порог уверенности для принятия решения

Если в main.py ещё нет CLI-аргументов — используйте его как модуль/скрипт по умолчанию или запустите ноутбуки для подготовки и тестов.

Подготовка данных
Скопируйте исходные записи в input/.

Откройте audio-prepare.ipynb и выполните ячейки для:

нормализации/обрезки тишины,

извлечения признаков (например, MFCC),

сохранения подготовленных фрагментов и меток.

Проверьте результаты в output/.

Обучение / Дообучение модели
Откройте Audio_Lerning_AutoEncoder.ipynb.

Настройте гиперпараметры (размер окна, частоту дискретизации, архитектуру).

Обучите модель и сохраните в models/ как new_modelX.h5.

Проверьте качество на валидации/тесте (метрики выведите в ноутбуке).

Интеграция с ESP32
Узел распознавания (ПК/RPi) после классификации отправляет числовой код команды.

Варианты транспорта:

ESP-NOW — беспроводная передача на ESP32.

Serial/USB/UART — проводное соединение для отладки.

На стороне ESP32 реализуйте обработчики команд (открыть/закрыть кисть, захват, позиция пальцев и т.п.) с использованием ШИМ/драйверов.

(Пример скетча для ESP32 планируется в каталоге firmware/esp32/.)

Репродуцируемость
Версия Python и ключевых библиотек фиксируются в requirements.txt.


Для крупных моделей используйте Git LFS:

bash
Копировать код
git lfs install
git lfs track "*.h5"
git add .gitattributes
git add models/*.h5 && git commit -m "Add models via LFS"
Дорожная карта
 Завершить CLI в main.py (все аргументы из раздела «Быстрый старт»)

 Перенести модели в models/ и подключить Git LFS

 Добавить примеры аудио (examples/) и скрипт быстрого теста

 Выложить минимальный скетч ESP32 (ESP-NOW)

 Настроить автотесты и CI (GitHub Actions)
